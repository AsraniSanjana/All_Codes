{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5ZuVHXy1AERyiOH5zLIjU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AsraniSanjana/All_Codes/blob/main/All_Semester_Codes/ML_sem7/models/practice_id3_c4_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    \"\"\"Contains the information of the node and another nodes of the Decision Tree.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.value = None\n",
        "        self.next = None\n",
        "        self.childs = None\n",
        "\n",
        "class DecisionTreeClassifier:\n",
        "    \"\"\"Decision Tree Classifier using ID3 algorithm.\"\"\"\n",
        "\n",
        "    def __init__(self, X, feature_names, labels):\n",
        "        self.X = X  # features or predictors\n",
        "        self.feature_names = feature_names  # name of the features\n",
        "        self.labels = labels  # categories\n",
        "        self.labelCategories = list(set(labels))  # unique categories\n",
        "        # number of instances of each category\n",
        "        self.labelCategoriesCount = [list(labels).count(x) for x in self.labelCategories]\n",
        "        self.node = None  # nodes\n",
        "        # calculate the initial entropy of the system\n",
        "        self.entropy = self._get_entropy([x for x in range(len(self.labels))])\n",
        "\n",
        "\n",
        "    def _get_entropy(self, x_ids):\n",
        "        \"\"\" Calculates the entropy.\n",
        "        Parameters\n",
        "        __________\n",
        "        :param x_ids: list, List containing the instances ID's\n",
        "        __________\n",
        "        :return: entropy: float, Entropy.\n",
        "        \"\"\"\n",
        "        # sorted labels by instance id\n",
        "        labels = [self.labels[i] for i in x_ids]\n",
        "        # count number of instances of each category\n",
        "        label_count = [labels.count(x) for x in self.labelCategories]\n",
        "        # calculate the entropy for each category and sum them\n",
        "        entropy = sum([-count / len(x_ids) * math.log(count / len(x_ids), 2)\n",
        "                      if count else 0\n",
        "                      for count in label_count\n",
        "                      ])\n",
        "\n",
        "        return entropy\n",
        "\n",
        "    def _get_information_gain(self, x_ids, feature_id):\n",
        "        \"\"\"Calculates the information gain for a given feature based on its entropy and the total entropy of the system.\n",
        "        Parameters\n",
        "        __________\n",
        "        :param x_ids: list, List containing the instances ID's\n",
        "        :param feature_id: int, feature ID\n",
        "        __________\n",
        "        :return: info_gain: float, the information gain for a given feature.\n",
        "        \"\"\"\n",
        "        # calculate total entropy\n",
        "        info_gain = self._get_entropy(x_ids)\n",
        "        # store in a list all the values of the chosen feature\n",
        "        x_features = [self.X[x][feature_id] for x in x_ids]\n",
        "        # get unique values\n",
        "        feature_vals = list(set(x_features))\n",
        "        # get frequency of each value\n",
        "        feature_v_count = [x_features.count(x) for x in feature_vals]\n",
        "        # get the feature values ids\n",
        "        feature_v_id = [\n",
        "            [x_ids[i]\n",
        "            for i, x in enumerate(x_features)\n",
        "            if x == y]\n",
        "            for y in feature_vals\n",
        "        ]\n",
        "\n",
        "        # compute the information gain with the chosen feature\n",
        "        info_gain_feature = sum([v_counts / len(x_ids) * self._get_entropy(v_ids)\n",
        "                            for v_counts, v_ids in zip(feature_v_count, feature_v_id)])\n",
        "\n",
        "        info_gain = info_gain - info_gain_feature\n",
        "\n",
        "        return info_gain\n",
        "\n",
        "\n",
        "    def _get_feature_max_information_gain(self, x_ids, feature_ids):\n",
        "        \"\"\"Finds the attribute/feature that maximizes the information gain.\n",
        "        Parameters\n",
        "        __________\n",
        "        :param x_ids: list, List containing the samples ID's\n",
        "        :param feature_ids: list, List containing the feature ID's\n",
        "        __________\n",
        "        :returns: string and int, feature and feature id of the feature that maximizes the information gain\n",
        "        \"\"\"\n",
        "        # get the entropy for each feature\n",
        "        features_entropy = [self._get_information_gain(x_ids, feature_id) for feature_id in feature_ids]\n",
        "        # find the feature that maximises the information gain\n",
        "        max_id = feature_ids[features_entropy.index(max(features_entropy))]\n",
        "\n",
        "        return self.feature_names[max_id], max_id\n",
        "\n",
        "\n",
        "    def id3(self):\n",
        "        \"\"\"Initializes ID3 algorithm to build a Decision Tree Classifier.\n",
        "        :return: None\n",
        "        \"\"\"\n",
        "        # assign an unique number to each instance\n",
        "        x_ids = [x for x in range(len(self.X))]\n",
        "        # assign an unique number to each featuer\n",
        "        feature_ids = [x for x in range(len(self.feature_names))]\n",
        "        # define node variable - instance of the class Node\n",
        "        self.node = self._id3_recv(x_ids, feature_ids, self.node)\n",
        "\n",
        "\n",
        "    def _id3_recv(self, x_ids, feature_ids, node):\n",
        "        \"\"\"ID3 algorithm. It is called recursively until some criteria is met.\n",
        "        Parameters\n",
        "        __________\n",
        "        :param x_ids: list, list containing the samples ID's\n",
        "        :param feature_ids: list, List containing the feature ID's\n",
        "        :param node: object, An instance of the class Nodes\n",
        "        __________\n",
        "        :returns: An instance of the class Node containing all the information of the nodes in the Decision Tree\n",
        "        \"\"\"\n",
        "        if not node:\n",
        "            node = Node()  # initialize nodes\n",
        "        # sorted labels by instance id\n",
        "        labels_in_features = [self.labels[x] for x in x_ids]\n",
        "        # if all the example have the same class (pure node), return node\n",
        "        if len(set(labels_in_features)) == 1:\n",
        "            node.value = self.labels[x_ids[0]]\n",
        "            return node\n",
        "        # if there are not more feature to compute, return node with the most probable class\n",
        "        if len(feature_ids) == 0:\n",
        "            node.value = max(set(labels_in_features), key=labels_in_features.count)  # compute mode\n",
        "            return node\n",
        "        # else...\n",
        "        # choose the feature that maximizes the information gain\n",
        "        best_feature_name, best_feature_id = self._get_feature_max_information_gain(x_ids, feature_ids)\n",
        "        node.value = best_feature_name\n",
        "        node.childs = []\n",
        "        # value of the chosen feature for each instance\n",
        "        feature_values = list(set([self.X[x][best_feature_id] for x in x_ids]))\n",
        "        # loop through all the values\n",
        "        for value in feature_values:\n",
        "            child = Node()\n",
        "            child.value = value  # add a branch from the node to each feature value in our feature\n",
        "            node.childs.append(child)  # append new child node to current node\n",
        "            child_x_ids = [x for x in x_ids if self.X[x][best_feature_id] == value]\n",
        "            if not child_x_ids:\n",
        "                child.next = max(set(labels_in_features), key=labels_in_features.count)\n",
        "                print('')\n",
        "            else:\n",
        "                if feature_ids and best_feature_id in feature_ids:\n",
        "                    to_remove = feature_ids.index(best_feature_id)\n",
        "                    feature_ids.pop(to_remove)\n",
        "                # recursively call the algorithm\n",
        "                child.next = self._id3_recv(child_x_ids, feature_ids, child.next)\n",
        "\n",
        "    # if all the example have the same class (pure node), return node\n",
        "                if len(set(labels_in_features)) == 1:\n",
        "                    node.value = self.labels[x_ids[0]]\n",
        "                    return node\n",
        "\n",
        "                # if there are not more feature to compute, return node with the most probable class\n",
        "                if len(feature_ids) == 0:\n",
        "                    node.value = max(set(labels_in_features), key=labels_in_features.count)  # compute mode\n",
        "                    return node\n",
        "\n",
        "                  # else...\n",
        "        # choose the feature that maximizes the information gain\n",
        "                best_feature_name, best_feature_id = self._get_feature_max_information_gain(x_ids, feature_ids)\n",
        "                node.value = best_feature_name\n",
        "                node.childs = []\n",
        "                # value of the chosen feature for each instance\n",
        "                feature_values = list(set([self.X[x][best_feature_id] for x in x_ids]))\n",
        "                # loop through all the values\n",
        "                for value in feature_values:\n",
        "                    child = Node()\n",
        "                    child.value = value  # add a branch from the node to each feature value in our feature\n",
        "                    node.childs.append(child)  # append new child node to current node\n",
        "                    child_x_ids = [x for x in x_ids if self.X[x][best_feature_id] == value] # instances that take the branch\n",
        "                    if not child_x_ids:\n",
        "                        child.next = max(set(labels_in_features), key=labels_in_features.count)\n",
        "                        print('')\n",
        "                    else:\n",
        "                        if feature_ids and best_feature_id in feature_ids:\n",
        "                            to_remove = feature_ids.index(best_feature_id)\n",
        "                            feature_ids.pop(to_remove)\n",
        "                        # recursively call the algorithm\n",
        "                        child.next = self._id3_recv(child_x_ids, feature_ids, child.next)\n",
        "                return node\n",
        "        return node"
      ],
      "metadata": {
        "id": "7c0KDj0vEqsS"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "# Define the Node class and DecisionTreeClassifier class here\n",
        "\n",
        "# Load the dataset\n",
        "data_df = pd.read_csv(\"Buy_Computer.csv\")\n",
        "\n",
        "\n",
        "# Extract features, feature_names, and labels from the dataset\n",
        "X = data_df[['age', 'income', 'student', 'credit_rating']].values\n",
        "feature_names = ['age', 'income', 'student', 'credit_rating']\n",
        "labels = data_df['Buy_Computer'].values\n",
        "\n",
        "# Create an instance of DecisionTreeClassifier\n",
        "dt_classifier = DecisionTreeClassifier(X, feature_names, labels)\n",
        "\n",
        "# Run the ID3 algorithm\n",
        "dt_classifier.id3()\n"
      ],
      "metadata": {
        "id": "9nojWeL8IuIB"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "data_df = pd.read_csv(\"happy_sad.csv\") # Buy_computer here is the dataset name\n",
        "\n",
        "class_labels = data_df['emotions'] # Buy_Computer here is the last colmn name : class label : yes or no\n",
        "dt_classifier = DecisionTreeClassifier(None,None,class_labels)  # Pass None for X and feature_names\n"
      ],
      "metadata": {
        "id": "tklMbADXKpY2"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FOR ID3:**\n",
        "\n",
        "\n",
        "1.   ENTROPY\n",
        "2.   INFO GAIN\n",
        "3.   GAIN\n",
        "\n",
        "**FOR C4.5:**\n",
        "\n",
        "1.   GAIN RATIO\n",
        "2.   SPLIT INFO\n",
        "\n",
        "\n",
        "**FOR CART:**\n",
        "\n",
        "1.   GINI INDEX\n",
        "2.   DELTA GINI"
      ],
      "metadata": {
        "id": "Bgrh-PE9_6lP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check intermediate calculations:"
      ],
      "metadata": {
        "id": "mHk-1B6udjTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tabulate import tabulate\n",
        "def getGain(attribute_name):\n",
        "    attribute_column = data_df[attribute_name]\n",
        "    class_labels = data_df['Buy_Computer']\n",
        "\n",
        "    # Create an instance of DecisionTreeClassifier\n",
        "    dt_classifier = DecisionTreeClassifier(None, None, class_labels)  # Pass None for X and feature_names\n",
        "\n",
        "    # Calculate entropy for the attribute values\n",
        "    attribute_values = attribute_column.unique()\n",
        "\n",
        "    entropies = []\n",
        "    weighted_entropies = []\n",
        "    values_counts = {}\n",
        "    for value in attribute_values:\n",
        "        subset_indices = attribute_column[attribute_column == value].index\n",
        "        entropy = dt_classifier._get_entropy(subset_indices)\n",
        "        entropies.append(entropy)\n",
        "        weight = len(subset_indices) / len(attribute_column)\n",
        "        weighted_entropy = entropy * weight\n",
        "        weighted_entropies.append(weighted_entropy)\n",
        "        values_counts[value] = len(subset_indices)\n",
        "\n",
        "\n",
        "    # Calculate information gain for the attribute\n",
        "    total_entropy = dt_classifier._get_entropy(attribute_column.index)\n",
        "    total_weighted_entropy = sum(weighted_entropies)\n",
        "    info_gain = total_weighted_entropy\n",
        "\n",
        "    # Calculate and display the final gain for the attribute\n",
        "    dataset_entropy = dt_classifier._get_entropy(attribute_column.index)\n",
        "    final_gain = dataset_entropy - info_gain\n",
        "\n",
        "\n",
        "    # Calculate split info for the attribute\n",
        "    total_tuples = len(data_df)\n",
        "    split_info = 0\n",
        "    for value_count in values_counts.values():\n",
        "        ratio = value_count / total_tuples\n",
        "        split_info -= ratio * math.log2(ratio)\n",
        "\n",
        "    gain_ratio = final_gain / split_info\n",
        "\n",
        "\n",
        "    header = [attribute_name] + list(set(class_labels)) + ['Total', 'Entropy', 'Weight']\n",
        "    column_width = max(len(name) for name in header) + 2\n",
        "    table_format = '|'.join('{{:<{}}}'.format(column_width) for _ in range(len(header)))\n",
        "\n",
        "    # Print the header\n",
        "    print(\"Values Counts, Entropies, and Weights for '{}' attribute:\".format(attribute_name))\n",
        "    print(table_format.format(*header))\n",
        "    print('|' + '=' * (column_width * len(header) + len(header) - 1) + '|')\n",
        "\n",
        "    # Print the rows\n",
        "    for value in values_counts:\n",
        "        subset_indices = attribute_column[attribute_column == value].index\n",
        "        class_counts = [sum((class_labels[index] == label) for index in subset_indices) for label in header[1:-3]]\n",
        "        total_count = values_counts[value]\n",
        "        entropy = calculate_entropy(class_labels[subset_indices])\n",
        "        weight = total_count / total_tuples\n",
        "        print(table_format.format(value, *class_counts, total_count, entropy, weight))\n",
        "\n",
        "    print(f\"\\nHence, Gain({attribute_name}) becomes {dataset_entropy:.4f} - {info_gain:.4f} = {final_gain:.4f}\")\n",
        "    print(f\"Split Info({attribute_name}) = {split_info:.4f}\")\n",
        "    print(f\"Gain Ratio({attribute_name}) = {final_gain:.4f} / {split_info:.4f} = {gain_ratio:.4f}\")\n",
        "    print(\"\\n_____________________________________________________________________________________________________________________\\n\")\n",
        "\n",
        "# getGain('color')\n",
        "# getGain('wig')\n",
        "# getGain('num_of_ears')\n",
        "#  or just do :\n",
        "for attribute_name in feature_names:\n",
        "    getGain(attribute_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nlbgxfjYXIh",
        "outputId": "214e7c04-657b-4f2f-c209-51d0d8d7c79e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Values Counts, Entropies, and Weights for 'age' attribute:\n",
            "age      |no       |yes      |Total    |Entropy  |Weight   \n",
            "|===========================================================|\n",
            "youth    |3        |2        |5        |0.9709505944546686|0.35714285714285715\n",
            "middle_age|0        |4        |4        |-0.0     |0.2857142857142857\n",
            "senior   |2        |3        |5        |0.9709505944546686|0.35714285714285715\n",
            "\n",
            "Hence, Gain(age) becomes 0.9403 - 0.6935 = 0.2467\n",
            "Split Info(age) = 1.5774\n",
            "Gain Ratio(age) = 0.2467 / 1.5774 = 0.1564\n",
            "\n",
            "_____________________________________________________________________________________________________________________\n",
            "\n",
            "Values Counts, Entropies, and Weights for 'income' attribute:\n",
            "income   |no       |yes      |Total    |Entropy  |Weight   \n",
            "|===========================================================|\n",
            "high     |2        |2        |4        |1.0      |0.2857142857142857\n",
            "medium   |2        |4        |6        |0.9182958340544896|0.42857142857142855\n",
            "low      |1        |3        |4        |0.8112781244591328|0.2857142857142857\n",
            "\n",
            "Hence, Gain(income) becomes 0.9403 - 0.9111 = 0.0292\n",
            "Split Info(income) = 1.5567\n",
            "Gain Ratio(income) = 0.0292 / 1.5567 = 0.0188\n",
            "\n",
            "_____________________________________________________________________________________________________________________\n",
            "\n",
            "Values Counts, Entropies, and Weights for 'student' attribute:\n",
            "student  |no       |yes      |Total    |Entropy  |Weight   \n",
            "|===========================================================|\n",
            "no       |4        |3        |7        |0.9852281360342515|0.5      \n",
            "yes      |1        |6        |7        |0.5916727785823275|0.5      \n",
            "\n",
            "Hence, Gain(student) becomes 0.9403 - 0.7885 = 0.1518\n",
            "Split Info(student) = 1.0000\n",
            "Gain Ratio(student) = 0.1518 / 1.0000 = 0.1518\n",
            "\n",
            "_____________________________________________________________________________________________________________________\n",
            "\n",
            "Values Counts, Entropies, and Weights for 'credit_rating' attribute:\n",
            "credit_rating  |no             |yes            |Total          |Entropy        |Weight         \n",
            "|===============================================================================================|\n",
            "fair           |2              |6              |8              |0.8112781244591328|0.5714285714285714\n",
            "excellent      |3              |3              |6              |1.0            |0.42857142857142855\n",
            "\n",
            "Hence, Gain(credit_rating) becomes 0.9403 - 0.8922 = 0.0481\n",
            "Split Info(credit_rating) = 0.9852\n",
            "Gain Ratio(credit_rating) = 0.0481 / 0.9852 = 0.0488\n",
            "\n",
            "_____________________________________________________________________________________________________________________\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_subdataset(data, attribute_name):\n",
        "    attribute_values = data[attribute_name].unique()\n",
        "\n",
        "    for value in attribute_values:\n",
        "        print(f\"Subdataset with '{attribute_name}' = '{value}':\")\n",
        "        subset_data = data[data[attribute_name] == value].reset_index(drop=True)\n",
        "\n",
        "        print(subset_data)  # Display the subset data\n",
        "        print(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "\n",
        "# Process each attribute\n",
        "feature_names = ['age', 'income', 'student', 'credit_rating']\n",
        "for attribute_name in feature_names:\n",
        "    process_subdataset(data_df, attribute_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNC1G4YmUIy6",
        "outputId": "1f1af86b-cecb-443a-e67e-da848d3a650d"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subdataset with 'age' = 'youth':\n",
            "   id    age  income student credit_rating Buy_Computer\n",
            "0   1  youth    high      no          fair           no\n",
            "1   2  youth    high      no     excellent           no\n",
            "2   8  youth  medium      no          fair           no\n",
            "3   9  youth     low     yes          fair          yes\n",
            "4  11  youth  medium     yes     excellent          yes\n",
            "============================================================\n",
            "\n",
            "Subdataset with 'age' = 'middle_age':\n",
            "   id         age  income student credit_rating Buy_Computer\n",
            "0   3  middle_age    high      no          fair          yes\n",
            "1   7  middle_age     low     yes     excellent          yes\n",
            "2  12  middle_age  medium      no     excellent          yes\n",
            "3  13  middle_age    high     yes          fair          yes\n",
            "============================================================\n",
            "\n",
            "Subdataset with 'age' = 'senior':\n",
            "   id     age  income student credit_rating Buy_Computer\n",
            "0   4  senior  medium      no          fair          yes\n",
            "1   5  senior     low     yes          fair          yes\n",
            "2   6  senior     low     yes     excellent           no\n",
            "3  10  senior  medium     yes          fair          yes\n",
            "4  14  senior  medium      no     excellent           no\n",
            "============================================================\n",
            "\n",
            "Subdataset with 'income' = 'high':\n",
            "   id         age income student credit_rating Buy_Computer\n",
            "0   1       youth   high      no          fair           no\n",
            "1   2       youth   high      no     excellent           no\n",
            "2   3  middle_age   high      no          fair          yes\n",
            "3  13  middle_age   high     yes          fair          yes\n",
            "============================================================\n",
            "\n",
            "Subdataset with 'income' = 'medium':\n",
            "   id         age  income student credit_rating Buy_Computer\n",
            "0   4      senior  medium      no          fair          yes\n",
            "1   8       youth  medium      no          fair           no\n",
            "2  10      senior  medium     yes          fair          yes\n",
            "3  11       youth  medium     yes     excellent          yes\n",
            "4  12  middle_age  medium      no     excellent          yes\n",
            "5  14      senior  medium      no     excellent           no\n",
            "============================================================\n",
            "\n",
            "Subdataset with 'income' = 'low':\n",
            "   id         age income student credit_rating Buy_Computer\n",
            "0   5      senior    low     yes          fair          yes\n",
            "1   6      senior    low     yes     excellent           no\n",
            "2   7  middle_age    low     yes     excellent          yes\n",
            "3   9       youth    low     yes          fair          yes\n",
            "============================================================\n",
            "\n",
            "Subdataset with 'student' = 'no':\n",
            "   id         age  income student credit_rating Buy_Computer\n",
            "0   1       youth    high      no          fair           no\n",
            "1   2       youth    high      no     excellent           no\n",
            "2   3  middle_age    high      no          fair          yes\n",
            "3   4      senior  medium      no          fair          yes\n",
            "4   8       youth  medium      no          fair           no\n",
            "5  12  middle_age  medium      no     excellent          yes\n",
            "6  14      senior  medium      no     excellent           no\n",
            "============================================================\n",
            "\n",
            "Subdataset with 'student' = 'yes':\n",
            "   id         age  income student credit_rating Buy_Computer\n",
            "0   5      senior     low     yes          fair          yes\n",
            "1   6      senior     low     yes     excellent           no\n",
            "2   7  middle_age     low     yes     excellent          yes\n",
            "3   9       youth     low     yes          fair          yes\n",
            "4  10      senior  medium     yes          fair          yes\n",
            "5  11       youth  medium     yes     excellent          yes\n",
            "6  13  middle_age    high     yes          fair          yes\n",
            "============================================================\n",
            "\n",
            "Subdataset with 'credit_rating' = 'fair':\n",
            "   id         age  income student credit_rating Buy_Computer\n",
            "0   1       youth    high      no          fair           no\n",
            "1   3  middle_age    high      no          fair          yes\n",
            "2   4      senior  medium      no          fair          yes\n",
            "3   5      senior     low     yes          fair          yes\n",
            "4   8       youth  medium      no          fair           no\n",
            "5   9       youth     low     yes          fair          yes\n",
            "6  10      senior  medium     yes          fair          yes\n",
            "7  13  middle_age    high     yes          fair          yes\n",
            "============================================================\n",
            "\n",
            "Subdataset with 'credit_rating' = 'excellent':\n",
            "   id         age  income student credit_rating Buy_Computer\n",
            "0   2       youth    high      no     excellent           no\n",
            "1   6      senior     low     yes     excellent           no\n",
            "2   7  middle_age     low     yes     excellent          yes\n",
            "3  11       youth  medium     yes     excellent          yes\n",
            "4  12  middle_age  medium      no     excellent          yes\n",
            "5  14      senior  medium      no     excellent           no\n",
            "============================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final code.... You can call the functions getGain(), process_subdatasets() as well to print the whole walk-through of algorithm."
      ],
      "metadata": {
        "id": "t_gQLk1odrsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "# Load the dataset\n",
        "data_df = pd.read_csv(\"Buy_Computer.csv\")  # Replace with your dataset\n",
        "\n",
        "# Define the Node class\n",
        "class Node:\n",
        "    def __init__(self, value=None):\n",
        "        self.value = value\n",
        "        self.branches = {}\n",
        "\n",
        "# Calculate the entropy of a dataset\n",
        "def calculate_entropy(data_df, target_column):\n",
        "    class_counts = data_df[target_column].value_counts()\n",
        "    total_instances = len(data_df)\n",
        "    entropy = 0\n",
        "    for class_count in class_counts:\n",
        "        class_probability = class_count / total_instances\n",
        "        entropy -= class_probability * math.log2(class_probability)\n",
        "    return entropy\n",
        "\n",
        "# Calculate the information gain for an attribute\n",
        "def calculate_information_gain(data_df, attribute, target_column):\n",
        "    total_entropy = calculate_entropy(data_df, target_column)\n",
        "    attribute_values = data_df[attribute].unique()\n",
        "    weighted_entropy = 0\n",
        "    for value in attribute_values:\n",
        "        subset = data_df[data_df[attribute] == value]\n",
        "        subset_entropy = calculate_entropy(subset, target_column)\n",
        "        value_probability = len(subset) / len(data_df)\n",
        "        weighted_entropy += value_probability * subset_entropy\n",
        "    information_gain = total_entropy - weighted_entropy\n",
        "    return information_gain\n",
        "\n",
        "# Function to print intermediate results\n",
        "def print_intermediate_results(attribute, information_gain, selected_tuples):\n",
        "    print(f\"Chosen Attribute: {attribute}\")\n",
        "    print(f\"Information Gain: {information_gain:.4f}\")\n",
        "    print(f\"Selected Tuples:\")\n",
        "    print(selected_tuples)\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "# Build the decision tree recursively\n",
        "def build_decision_tree(data_df, target_column, attributes):\n",
        "    # Stopping conditions\n",
        "    if data_df[target_column].nunique() == 1:\n",
        "        return Node(data_df[target_column].iloc[0])\n",
        "    if len(attributes) == 0:\n",
        "        majority_class = data_df[target_column].mode()[0]\n",
        "        return Node(majority_class)\n",
        "\n",
        "    # Calculate information gain for each attribute\n",
        "    information_gains = [calculate_information_gain(data_df, attribute, target_column) for attribute in attributes]\n",
        "    selected_attribute_idx = information_gains.index(max(information_gains))\n",
        "    selected_attribute = attributes[selected_attribute_idx]\n",
        "\n",
        "    root = Node(selected_attribute)\n",
        "    remaining_attributes = [attribute for idx, attribute in enumerate(attributes) if idx != selected_attribute_idx]\n",
        "    attribute_values = data_df[selected_attribute].unique()\n",
        "    for value in attribute_values:\n",
        "        subset = data_df[data_df[selected_attribute] == value]\n",
        "        if len(subset) == 0:\n",
        "            majority_class = data_df[target_column].mode()[0]\n",
        "            root.branches[value] = Node(majority_class)\n",
        "        else:\n",
        "            print_intermediate_results(selected_attribute, information_gains[selected_attribute_idx], subset)\n",
        "            root.branches[value] = build_decision_tree(subset, target_column, remaining_attributes)\n",
        "\n",
        "    return root\n",
        "\n",
        "# Call the build_decision_tree function\n",
        "target_column = \"Buy_Computer\"\n",
        "attributes = [\"age\", \"income\", \"student\", \"credit_rating\"]\n",
        "decision_tree = build_decision_tree(data_df, target_column, attributes)\n",
        "\n",
        "# Function to print the decision tree\n",
        "def print_decision_tree(node, depth=0):\n",
        "    if node.value is not None:\n",
        "        print(\"  \" * depth, node.value)\n",
        "    for value, branch in node.branches.items():\n",
        "        print(\"  \" * (depth + 1), value, end=\": \")\n",
        "        print_decision_tree(branch, depth + 1)\n",
        "\n",
        "# Print the decision tree\n",
        "print_decision_tree(decision_tree)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6PkM-grbx3J",
        "outputId": "fe6adcec-7a8c-4486-bae1-2957619a1815"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen Attribute: age\n",
            "Information Gain: 0.2467\n",
            "Selected Tuples:\n",
            "    id    age  income student credit_rating Buy_Computer\n",
            "0    1  youth    high      no          fair           no\n",
            "1    2  youth    high      no     excellent           no\n",
            "7    8  youth  medium      no          fair           no\n",
            "8    9  youth     low     yes          fair          yes\n",
            "10  11  youth  medium     yes     excellent          yes\n",
            "========================================\n",
            "Chosen Attribute: student\n",
            "Information Gain: 0.9710\n",
            "Selected Tuples:\n",
            "   id    age  income student credit_rating Buy_Computer\n",
            "0   1  youth    high      no          fair           no\n",
            "1   2  youth    high      no     excellent           no\n",
            "7   8  youth  medium      no          fair           no\n",
            "========================================\n",
            "Chosen Attribute: student\n",
            "Information Gain: 0.9710\n",
            "Selected Tuples:\n",
            "    id    age  income student credit_rating Buy_Computer\n",
            "8    9  youth     low     yes          fair          yes\n",
            "10  11  youth  medium     yes     excellent          yes\n",
            "========================================\n",
            "Chosen Attribute: age\n",
            "Information Gain: 0.2467\n",
            "Selected Tuples:\n",
            "    id         age  income student credit_rating Buy_Computer\n",
            "2    3  middle_age    high      no          fair          yes\n",
            "6    7  middle_age     low     yes     excellent          yes\n",
            "11  12  middle_age  medium      no     excellent          yes\n",
            "12  13  middle_age    high     yes          fair          yes\n",
            "========================================\n",
            "Chosen Attribute: age\n",
            "Information Gain: 0.2467\n",
            "Selected Tuples:\n",
            "    id     age  income student credit_rating Buy_Computer\n",
            "3    4  senior  medium      no          fair          yes\n",
            "4    5  senior     low     yes          fair          yes\n",
            "5    6  senior     low     yes     excellent           no\n",
            "9   10  senior  medium     yes          fair          yes\n",
            "13  14  senior  medium      no     excellent           no\n",
            "========================================\n",
            "Chosen Attribute: credit_rating\n",
            "Information Gain: 0.9710\n",
            "Selected Tuples:\n",
            "   id     age  income student credit_rating Buy_Computer\n",
            "3   4  senior  medium      no          fair          yes\n",
            "4   5  senior     low     yes          fair          yes\n",
            "9  10  senior  medium     yes          fair          yes\n",
            "========================================\n",
            "Chosen Attribute: credit_rating\n",
            "Information Gain: 0.9710\n",
            "Selected Tuples:\n",
            "    id     age  income student credit_rating Buy_Computer\n",
            "5    6  senior     low     yes     excellent           no\n",
            "13  14  senior  medium      no     excellent           no\n",
            "========================================\n",
            " age\n",
            "   youth:    student\n",
            "     no:      no\n",
            "     yes:      yes\n",
            "   middle_age:    yes\n",
            "   senior:    credit_rating\n",
            "     fair:      yes\n",
            "     excellent:      no\n"
          ]
        }
      ]
    }
  ]
}