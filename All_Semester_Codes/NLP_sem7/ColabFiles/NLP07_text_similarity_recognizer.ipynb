{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzfu4q62Q+G9gMKcZe6/Jf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AsraniSanjana/All_Codes/blob/main/All_Semester_Codes/NLP_sem7/ColabFiles/NLP07_text_similarity_recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NAME:** SANJANA ASRANI\n",
        "\n",
        "**DIV:** D17B\n",
        "\n",
        "**ROLL NO.**: 01\n",
        "\n",
        "**NLP LAB-07 :** Implement a Text Similarity Recognizer for the chosen text documents."
      ],
      "metadata": {
        "id": "m2jjY_J2E7Vx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section Text similarity detection in NLP\n",
        "\n",
        "1. **Vector Representation**: First, text documents need to be converted into numerical vectors because mathematical operations like cosine similarity require numeric input. Common techniques for this include Word Embeddings (e.g., Word2Vec, GloVe) or TF-IDF (Term Frequency-Inverse Document Frequency) vectors.\n",
        "\n",
        "2. **Vector Space Model**: The vector representation places each document in a high-dimensional vector space, where each dimension corresponds to a word or term. The values in the vector indicate the importance or frequency of each term in the document.\n",
        "\n",
        "3. **Cosine Similarity**: Cosine similarity measures the cosine of the angle between two vectors. In this context, it calculates the similarity between two text document vectors.\n",
        "\n",
        "   - A similarity of 1 means the vectors are identical.\n",
        "   - A similarity of 0 means the vectors are orthogonal (completely dissimilar).\n",
        "   - A similarity of -1 means the vectors are diametrically opposed.\n",
        "\n",
        "\n",
        "4. **Application**: Cosine similarity is widely used in NLP for various tasks, such as document retrieval, plagiarism detection, recommendation systems, and clustering similar documents.\n",
        "\n",
        "it has its limitations though, such as not considering the meaning or semantics of words. More advanced techniques like Word Embeddings capture semantic relationships better, but they often complement cosine similarity in NLP tasks."
      ],
      "metadata": {
        "id": "ycMUJunSFaqw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwXmgVp67dHm"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgniiNyYCxPj",
        "outputId": "666b89db-a05d-4bf4-b1d6-07e01d237d2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example data\n",
        "# documents = [\" Corruption in India remains a pervasive issue, affecting governance, business, and daily life. It impedes development, erodes trust, and demands systemic reforms for a more transparent and accountable society.\",\n",
        "#              \"Corruption in India often normalizes through social acceptance and blurred lines between donations and bribes. Charitable contributions may conceal unethical intentions, perpetuating systemic corruption and undermining genuine philanthropy.\",\n",
        "#              \"International Anti-Corruption Day is observed annually on December 9th. It aims to raise awareness about the detrimental effects of corruption globally, promote transparency, and encourage collective efforts to combat this pervasive issue.\",\n",
        "#              \"International Anti-Corruption Day is observed annually on December 9th. It aims to raise awareness about the detrimental effects of corruption globally, promote transparency, and encourage collective efforts to combat this pervasive issue.\"\n",
        "#              ]\n",
        "\n",
        "documents = [\" The best italian restaurant enjoy the best pasta\",    #0\n",
        "             \"American restaurant enjoy the best hamburger\",         #1\n",
        "             \"The best italian restaurant also speaks french while serving pasta\",            #2\n",
        "             \"The best the best American restaurant\"                 #3\n",
        "             ]\n",
        "\n",
        "# Tokenization and preprocessing\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "def preprocess(text):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    words = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words]\n",
        "    return \" \".join(words)\n",
        "\n",
        "preprocessed_documents = [preprocess(doc) for doc in documents]\n",
        "\n",
        "preprocessed_documents"
      ],
      "metadata": {
        "id": "iTKRYTqKCza2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a8a2967-5123-4619-efc7-22853de18f4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['best italian restaurant enjoy best pasta',\n",
              " 'american restaurant enjoy best hamburger',\n",
              " 'best italian restaurant also speaks french serving pasta',\n",
              " 'best best american restaurant']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed_documents)\n"
      ],
      "metadata": {
        "id": "PBvRBwgWC0z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n"
      ],
      "metadata": {
        "id": "WbMzB87JC2hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "similarity_score = cosine_similarities[0][2]  # same text\n",
        "similarity_score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIW4ULxbC3gS",
        "outputId": "461b2143-ccff-4038-e6af-3b5756cb37cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4767406715463728"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_score = cosine_similarities[3][3]\n",
        "similarity_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jGRYO-wEwn6",
        "outputId": "aafa1474-bcd2-4a2d-c08b-4e3ec3358806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999999999999999"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}