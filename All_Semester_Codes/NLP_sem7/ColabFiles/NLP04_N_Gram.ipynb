{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORzrXHjpzbu/C+tkyKea2q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AsraniSanjana/All_Codes/blob/main/All_Semester_Codes/NLP_sem7/ColabFiles/NLP04_N_Gram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# D17B_01_Sanjana Asrani\n",
        "NLP\n",
        "Lab 04 : N gram Language Model"
      ],
      "metadata": {
        "id": "fK2ha_JEK2BY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDm0PeRTKyO3",
        "outputId": "c5da3ab7-4c27-4351-b5a2-e1a98bc7ba14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting Probability of a sentence\n",
        "\n",
        "Considering bi-grams and uni-grams. similar implementation for trigram can also be done."
      ],
      "metadata": {
        "id": "tlXcKdWIOWXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "query_sentence = [\"<s>\", \"i\", \"i\", \"am\", \"not\", \"</s>\"]\n",
        "'''\n",
        "'''\n",
        "corpus_text = [\n",
        "    \"<s> i am a human </s>\",\n",
        "    \"<s> i am not a store </s>\",\n",
        "    \"<s> i i live in mumbai </s>\"\n",
        "]\n",
        "'''\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhOoSIUaLnw6",
        "outputId": "c663485a-38cf-49ba-beea-153838e7a73a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting n-grams"
      ],
      "metadata": {
        "id": "mvyE3R4-LpCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def n_grams(text,n):\n",
        "\ttokens=re.split(\"\\\\s+\",text)\n",
        "\tngrams= [ ]\n",
        "\tfor i in range (len(tokens)-n+1):\n",
        "\t\ttemp=[tokens[j] for j in range(i, i+n)]\n",
        "\t\tngrams.append(\" \".join(temp))\n",
        "\treturn ngrams\n",
        "text=\"the quick brown fox jumps over the lazy dog\";\n",
        "n_grams(text,3)       # trigram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5cYKgjSRvsk",
        "outputId": "b0194b09-ad12-4f56-aa36-8c6807fd337f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the quick brown',\n",
              " 'quick brown fox',\n",
              " 'brown fox jumps',\n",
              " 'fox jumps over',\n",
              " 'jumps over the',\n",
              " 'over the lazy',\n",
              " 'the lazy dog']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "    corpus_text = [\n",
        "        \"<s> i am a human </s>\",\n",
        "        \"<s> i am not a store </s>\",\n",
        "        \"<s> i i live in mumbai </s>\"\n",
        "    ]\n",
        "'''"
      ],
      "metadata": {
        "id": "HAVMrGFSM0Ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "24b11100-bf96-4322-acd2-e7ffc378028d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    corpus_text = [\\n        \"<s> i am a human </s>\",\\n        \"<s> i am not a store </s>\",\\n        \"<s> i i live in mumbai </s>\"\\n    ]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import math\n",
        "import random\n",
        "from nltk.probability import FreqDist, ConditionalFreqDist\n",
        "from nltk import bigrams, word_tokenize\n",
        "from tabulate import tabulate\n",
        "\n",
        "def calculate_counts(text_data):\n",
        "    unigrams = []\n",
        "    bigrams = []\n",
        "    unigram_counts = {}\n",
        "    bigram_counts = {}\n",
        "    word_count = 0\n",
        "\n",
        "    for sentence in text_data:\n",
        "        for i in range(len(sentence) - 1):\n",
        "            unigrams.append(sentence[i])\n",
        "            bigrams.append((sentence[i], sentence[i + 1]))\n",
        "\n",
        "            if (sentence[i], sentence[i + 1]) in bigram_counts:\n",
        "                bigram_counts[(sentence[i], sentence[i + 1])] += 1\n",
        "            else:\n",
        "                bigram_counts[(sentence[i], sentence[i + 1])] = 1\n",
        "\n",
        "        unigrams.append(sentence[i + 1])\n",
        "\n",
        "        for i in range(len(sentence)):\n",
        "            if sentence[i] in unigram_counts:\n",
        "                unigram_counts[sentence[i]] += 1\n",
        "            else:\n",
        "                unigram_counts[sentence[i]] = 1\n",
        "\n",
        "            word_count += 1\n",
        "\n",
        "    return unigrams, bigrams, bigram_counts, unigram_counts, word_count\n",
        "\n",
        "def calculate_unigram_probabilities(unigrams, unigram_counts, word_count):\n",
        "    probabilities = {}\n",
        "    for unigram in unigrams:\n",
        "        probabilities[unigram] = float(unigram_counts[unigram] / word_count)\n",
        "    return probabilities\n",
        "\n",
        "def calculate_bigram_probabilities(bigrams, bigram_counts, unigram_counts, unigram_probabilities, smooth):\n",
        "    probabilities = {}\n",
        "    for bigram in bigrams:\n",
        "        word_1 = bigram[0]\n",
        "\n",
        "        if bigram in bigram_counts and word_1 in unigram_counts:\n",
        "            probabilities[bigram] = float(bigram_counts[bigram] / unigram_counts[word_1])\n",
        "        else:\n",
        "            probabilities[bigram] = 0\n",
        "\n",
        "        if smooth:\n",
        "            if word_1 in unigram_counts:\n",
        "                probabilities[bigram] = (0.5 * probabilities[bigram]) + (0.5 * unigram_probabilities[word_1])\n",
        "            else:\n",
        "                probabilities[bigram] = 0.5 * probabilities[bigram]\n",
        "\n",
        "    return probabilities\n",
        "\n",
        "def calculate_sentence_probability(sentence, unigram_counts, bigram_counts, unigram_probabilities, word_count, smooth, use_log):\n",
        "    sentence_probability = 1\n",
        "    if use_log:\n",
        "        sentence_probability = 0\n",
        "\n",
        "    for i in range(len(sentence) - 1):\n",
        "        bigram_probability = calculate_bigram_probabilities([(sentence[i], sentence[i + 1])], bigram_counts, unigram_counts, unigram_probabilities, smooth=True)\n",
        "        bigram_probability = bigram_probability[(sentence[i], sentence[i + 1])]\n",
        "\n",
        "        if use_log:\n",
        "            sentence_probability += math.log(bigram_probability, 2)\n",
        "        else:\n",
        "            sentence_probability *= bigram_probability\n",
        "\n",
        "    if use_log:\n",
        "        return math.pow(2, sentence_probability)\n",
        "    else:\n",
        "        return sentence_probability\n",
        "\n",
        "def augment_sentence(bigram_counts, unigram_counts, unigram_probabilities, smooth, word_count):\n",
        "    sentence = '<s>'\n",
        "    previous_word = '<s>'\n",
        "    while previous_word != '</s>':\n",
        "        potential_successors = {}\n",
        "        for bigram in list(bigram_counts.keys()):\n",
        "            if previous_word == bigram[0]:\n",
        "                successor = bigram[1]\n",
        "\n",
        "                bigram_probability = calculate_bigram_probabilities([(previous_word, successor)], bigram_counts, unigram_counts, unigram_probabilities, smooth=True)\n",
        "                bigram_probability = bigram_probability[(previous_word, successor)]\n",
        "                potential_successors[successor] = bigram_probability\n",
        "\n",
        "        divisor = sum(potential_successors.values())\n",
        "        for successor in potential_successors:\n",
        "            potential_successors[successor] = potential_successors[successor] / divisor\n",
        "\n",
        "        next_word = random.choices(list(potential_successors.keys()), weights=potential_successors.values(), k=1)[0]\n",
        "        sentence = sentence + ' ' + next_word\n",
        "        previous_word = next_word\n",
        "\n",
        "    if previous_word != '</s>':\n",
        "        sentence = sentence + ' </s>'\n",
        "\n",
        "    return sentence\n",
        "\n",
        "def main():\n",
        "    smooth = True\n",
        "    use_log = True\n",
        "    corpus_text = [\n",
        "        \"<s> man marries women </s>\",\n",
        "        \"<s> woman marries man </s>\",\n",
        "        \"<s> woman marries woman </s>\",\n",
        "        \"<s> man divorces woman </s>\",\n",
        "        \"<s> woman divorces man </s>\"\n",
        "    ]\n",
        "\n",
        "    corpus = [re.split(r'\\s+', line.strip('\\n\"')) for line in corpus_text]\n",
        "\n",
        "    unigrams, bigrams, bigram_counts, unigram_counts, word_count = calculate_counts(corpus)\n",
        "    unigram_probabilities = calculate_unigram_probabilities(unigrams, unigram_counts, word_count)\n",
        "    bigram_probabilities = calculate_bigram_probabilities(bigrams, bigram_counts, unigram_counts, unigram_probabilities, smooth)\n",
        "\n",
        "    # query_sentence = [\"<s>\", \"i\", \"i\", \"am\", \"not\", \"</s>\"]\n",
        "    query_sentence = [\"<s>\", \"man\", \"marries\", \"man\",\"</s>\"]\n",
        "\n",
        "    # Print Unigram Count Table\n",
        "    unigram_count_table = [[\"Unigram\"] + query_sentence]\n",
        "    unigram_count_table.append([\"Count\"] + [unigram_counts[word] for word in query_sentence])\n",
        "    print(\"Unigram Count Table:\")\n",
        "    print(tabulate(unigram_count_table, tablefmt=\"grid\"))\n",
        "\n",
        "    # Print Bigram Count Table\n",
        "    bigram_count_table = [[\"\"] + query_sentence]\n",
        "    for word1 in query_sentence:\n",
        "        row = [word1]\n",
        "        for word2 in query_sentence:\n",
        "            count = bigram_counts.get((word1, word2), 0)\n",
        "            row.append(count)\n",
        "        bigram_count_table.append(row)\n",
        "    print(\"\\nBigram Count Table:\")\n",
        "    print(tabulate(bigram_count_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
        "\n",
        "    sentence_probability = calculate_sentence_probability(query_sentence, unigram_counts, bigram_counts, unigram_probabilities, word_count, smooth, use_log)\n",
        "\n",
        "\n",
        " # Calculate the bigram probability table\n",
        "    bigram_prob_table = [[\"\"] + query_sentence]\n",
        "    for word1 in query_sentence:\n",
        "        row = [word1]\n",
        "        for word2 in query_sentence:\n",
        "            bigram_count = bigram_counts.get((word1, word2), 0)\n",
        "            unigram_count = unigram_counts.get(word1, 0)  # Use get() to avoid KeyError\n",
        "            prob = bigram_count / unigram_count if unigram_count != 0 else 0\n",
        "            row.append(prob)\n",
        "        bigram_prob_table.append(row)\n",
        "\n",
        "    # Print Bigram Probability Table\n",
        "    print(\"\\nBigram Probability Table:\")\n",
        "    print(tabulate(bigram_prob_table, headers=\"firstrow\", tablefmt=\"grid\"))\n",
        "\n",
        "    # Calculate sentence probability using diagonals of the bigram probability table\n",
        "    sentence_probability = 1.0\n",
        "    for i in range(len(query_sentence) - 1):\n",
        "        word1, word2 = query_sentence[i], query_sentence[i + 1]\n",
        "        bigram_prob = bigram_probabilities.get((word1, word2), 0)\n",
        "        sentence_probability *= bigram_prob\n",
        "\n",
        "    # print(\"\\nSentence Probability:\", sentence_probability)\n",
        "    sentence_probability = calculate_sentence_probability(query_sentence, unigram_counts, bigram_counts, unigram_probabilities, word_count, smooth, use_log)\n",
        "\n",
        "    # Print sentence probability\n",
        "    print(\"\\nSentence Probability:\", sentence_probability)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUikrrnRQI3-",
        "outputId": "45e46686-383b-460f-cfc0-1f0a7bebc2a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Count Table:\n",
            "+---------+-----+-----+---------+-----+------+\n",
            "| Unigram | <s> | man | marries | man | </s> |\n",
            "+---------+-----+-----+---------+-----+------+\n",
            "| Count   | 5   | 4   | 3       | 4   | 5    |\n",
            "+---------+-----+-----+---------+-----+------+\n",
            "\n",
            "Bigram Count Table:\n",
            "+---------+-------+-------+-----------+-------+--------+\n",
            "|         |   <s> |   man |   marries |   man |   </s> |\n",
            "+=========+=======+=======+===========+=======+========+\n",
            "| <s>     |     0 |     2 |         0 |     2 |      0 |\n",
            "+---------+-------+-------+-----------+-------+--------+\n",
            "| man     |     0 |     0 |         1 |     0 |      2 |\n",
            "+---------+-------+-------+-----------+-------+--------+\n",
            "| marries |     0 |     1 |         0 |     1 |      0 |\n",
            "+---------+-------+-------+-----------+-------+--------+\n",
            "| man     |     0 |     0 |         1 |     0 |      2 |\n",
            "+---------+-------+-------+-----------+-------+--------+\n",
            "| </s>    |     0 |     0 |         0 |     0 |      0 |\n",
            "+---------+-------+-------+-----------+-------+--------+\n",
            "\n",
            "Bigram Probability Table:\n",
            "+---------+-------+----------+-----------+----------+--------+\n",
            "|         |   <s> |      man |   marries |      man |   </s> |\n",
            "+=========+=======+==========+===========+==========+========+\n",
            "| <s>     |     0 | 0.4      |      0    | 0.4      |    0   |\n",
            "+---------+-------+----------+-----------+----------+--------+\n",
            "| man     |     0 | 0        |      0.25 | 0        |    0.5 |\n",
            "+---------+-------+----------+-----------+----------+--------+\n",
            "| marries |     0 | 0.333333 |      0    | 0.333333 |    0   |\n",
            "+---------+-------+----------+-----------+----------+--------+\n",
            "| man     |     0 | 0        |      0.25 | 0        |    0.5 |\n",
            "+---------+-------+----------+-----------+----------+--------+\n",
            "| </s>    |     0 | 0        |      0    | 0        |    0   |\n",
            "+---------+-------+----------+-----------+----------+--------+\n",
            "\n",
            "Sentence Probability: 0.004600199999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting the next word\n",
        "using the same way, the most probable next word can be estimated."
      ],
      "metadata": {
        "id": "U7dIkM16SE-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    corpus_text = [\n",
        "        \"<s> i am jack </s>\",\n",
        "        \"<s> jack i am </s>\",\n",
        "        \"<s> jack i like </s>\",\n",
        "        \"<s> jack i do like </s>\",\n",
        "        \"<s> do i like jack </s>\"\n",
        "    ]\n",
        "\n",
        "    # 1. <s> jack\n",
        "    # 2. <s> jack i do\n",
        "    # 3. jack i am jack\n",
        "    # 4. do i like"
      ],
      "metadata": {
        "id": "D7ocHEaAmYUe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}